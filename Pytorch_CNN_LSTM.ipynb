{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adrien Hernandez Homework 1 - PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "310efd92386a4757a767d5204b08a865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8346dadd8dcd437f9d0c73a8e86d4503",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87cad6ba7ef84d03a7f8c0cb37ec01ec",
              "IPY_MODEL_b712d5d1ba464a378c00dbb2aec6dd8c"
            ]
          }
        },
        "8346dadd8dcd437f9d0c73a8e86d4503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87cad6ba7ef84d03a7f8c0cb37ec01ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f3b4a3b037d47cb8ba1196d7dbd3b98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f3ef2c146bf4dd38424170b3090b055"
          }
        },
        "b712d5d1ba464a378c00dbb2aec6dd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_adbb9a799ba44a91b927b44d0c27e6d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:04, 37859309.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_44a89539615b4132a01ca7f5223ca281"
          }
        },
        "0f3b4a3b037d47cb8ba1196d7dbd3b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f3ef2c146bf4dd38424170b3090b055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adbb9a799ba44a91b927b44d0c27e6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "44a89539615b4132a01ca7f5223ca281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdrienHdz/Deep_Learning_HEC/blob/master/Pytorch_CNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_LTBtfMBvW_",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning II: Deep Learning and Applications\n",
        "# Homework 1\n",
        "\n",
        "**Due date: Feb 16**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T33dD1e8tii2",
        "colab_type": "text"
      },
      "source": [
        "Install PyTorch and Skorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJB3VQYDCUmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "43ab27ff-b2fb-4f7b-f517-f2b029b18ba2"
      },
      "source": [
        "!pip install -q torch skorch torchvision torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███                             | 10kB 27.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 5.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 4.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l_Dl6qxCXmv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c0bbb1f4-081a-464e-bf46-a34c2767e83a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import skorch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uevQtU7NtZ_-",
        "colab_type": "text"
      },
      "source": [
        "## 1. Tensor Operations (20 points)\n",
        "\n",
        "Tensor operations are important in deep learning models. In this part, you are required to implement some common tensor operations in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DeQOItkeQCx",
        "colab_type": "text"
      },
      "source": [
        "### 1) Tensor squeezing, unsqueezing and viewing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAOmBE5ODwpP",
        "colab_type": "text"
      },
      "source": [
        "Tensor squeezing, unsqueezing and viewing are important methods to change the dimension of a Tensor, and the corresponding functions are [torch.squeeze](https://pytorch.org/docs/stable/torch.html#torch.squeeze), [torch.unsqueeze](https://pytorch.org/docs/stable/torch.html#torch.unsqueeze) and [torch.Tensor.view](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view). Please read the documents of the functions, and finish the following practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVrM80YxFSjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "933f2576-b413-4516-a3f8-5fa4fbe60b38"
      },
      "source": [
        "# x is a tensor with size being (3, 2)\n",
        "x = torch.Tensor([[1, 2], \n",
        "                  [3, 4], \n",
        "                  [5, 6]])\n",
        "x.shape\n",
        "# Add two new dimensions to x by using the function torch.unsqueeze, so that the size of x becomes (3, 1, 2, 1).\n",
        "x = torch.unsqueeze(torch.unsqueeze(x,1),-1)\n",
        "print(x.shape)\n",
        "# Remove the two dimensions justed added by using the function torch.squeeze, and change the size of x back to (3, 2).\n",
        "x = torch.squeeze(torch.squeeze(x,-1),1)\n",
        "print(x.shape)\n",
        "# x is now a two-dimensional tensor, or in other words a matrix. Now use the function torch.Tensor.view and change x to a one-dimensional vector with size being (6).\n",
        "x = torch.Tensor.view(x,6)\n",
        "print(x.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 2, 1])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liuR-U0wea0n",
        "colab_type": "text"
      },
      "source": [
        "### 2) Tensor concatenation and stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkbnt6v8Bo-j",
        "colab_type": "text"
      },
      "source": [
        "Tensor concatenation and stack are operations to combine small tensors into big tensors. The corresponding functions are [torch.cat](https://pytorch.org/docs/stable/torch.html#torch.cat) and [torch.stack](https://pytorch.org/docs/stable/torch.html#torch.stack). Please read the documents of the functions, and finish the following practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9KqXu3Stfjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "97f17754-1e49-4a77-df8a-46a1200ea170"
      },
      "source": [
        "# x is a tensor with size being (3, 2)\n",
        "x = torch.Tensor([[1, 2], [3, 4], [5, 6]])\n",
        "\n",
        "# y is a tensor with size being (3, 2)\n",
        "y = torch.Tensor([[-1, -2], [-3, -4], [-5, -6]])\n",
        "\n",
        "# Our goal is to generate a tensor z with size as (2, 3, 2), and z[0,:,:] = x, z[1,:,:] = y.\n",
        "\n",
        "# Use torch.stack to generate such a z\n",
        "z = torch.stack((x,y),0)\n",
        "print(z[0,:,:])\n",
        "# Use torch.cat and torch.unsqueeze to generate such a z\n",
        "z = torch.cat((torch.unsqueeze(x,0),torch.unsqueeze(y,0)))\n",
        "print(z[1,:,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1., -2.],\n",
              "        [-3., -4.],\n",
              "        [-5., -6.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGw4eEo-eeHm",
        "colab_type": "text"
      },
      "source": [
        "### 3) Tensor expansion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAII9eJgJFK2",
        "colab_type": "text"
      },
      "source": [
        "Tensor expansion is to expand a tensor into a larger tensor along singleton dimensions. The corresponding functions are [torch.Tensor.expand](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand) and [torch.Tensor.expand_as](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.expand_as). Please read the documents of the functions, and finish the following practice. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQbFte-AJzVL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0505d6ed-fcff-40b1-d373-2510a4deb373"
      },
      "source": [
        "# x is a tensor with size being (3)\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "\n",
        "# Our goal is to generate a tensor z with size (2, 3), so that z[0,:,:] = x, z[1,:,:] = x.\n",
        "\n",
        "# [TO DO]\n",
        "# Change the size of x into (1, 3) by using torch.unsqueeze.\n",
        "x = torch.unsqueeze(x,0)\n",
        "print(x.shape)\n",
        "\n",
        "# [TO DO]\n",
        "# Then expand the new tensor to the target tensor by using torch.Tensor.expand.\n",
        "z = x.expand(2,-1)\n",
        "print(z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3])\n",
            "torch.Size([2, 3])\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rFL_Shoef3m",
        "colab_type": "text"
      },
      "source": [
        "### 4) Tensor reduction in a given dimension"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmEoJVw0LL9H",
        "colab_type": "text"
      },
      "source": [
        "In deep learning, we often need to compute the mean/sum/max/min value in a given dimension of a tensor. Please read the document of [torch.mean](https://pytorch.org/docs/stable/torch.html#torch.mean), [torch.sum](https://pytorch.org/docs/stable/torch.html#torch.sum), [torch.max](https://pytorch.org/docs/stable/torch.html#torch.max), [torch.min](https://pytorch.org/docs/stable/torch.html#torch.min), [torch.topk](https://pytorch.org/docs/stable/torch.html#torch.topk), and finish the following practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7dlZwe4MNxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "1148ec88-6f73-4cdc-8471-40d431ca429b"
      },
      "source": [
        "# x is a random tensor with size being (10, 50)\n",
        "x = torch.randn(10, 50)\n",
        "\n",
        "# Compute the mean value for each row of x.\n",
        "# You need to generate a tensor x_mean of size (10), and x_mean[k, :] is the mean value of the k-th row of x.\n",
        "x_mean = torch.mean(x,1)\n",
        "print(x_mean[3, ])\n",
        "\n",
        "# Compute the sum value for each row of x.\n",
        "# You need to generate a tensor x_sum of size (10).\n",
        "x_sum = torch.sum(x,1)\n",
        "print(x_sum.shape)\n",
        "\n",
        "# Compute the max value for each row of x.\n",
        "# You need to generate a tensor x_max of size (10).\n",
        "x_max = torch.max(x,1)[0]\n",
        "print(x_max.shape)\n",
        "\n",
        "# Compute the min value for each row of x.\n",
        "# You need to generate a tensor x_min of size (10).\n",
        "x_min = torch.min(x,1)[0]\n",
        "print(x_min.shape)\n",
        "\n",
        "# Compute the top-5 values for each row of x.\n",
        "# You need to generate a tensor x_mean of size (10, 5), and x_top[k, :] is the top-5 values of each row in x.\n",
        "x_mean_xtop = x.topk(5,1).values\n",
        "print((x_mean_xtop.shape))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n",
            "torch.Size([10])\n",
            "torch.Size([10])\n",
            "torch.Size([10, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I49qjiqHB9oa",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks (40 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JePbG5pSt1xv",
        "colab_type": "text"
      },
      "source": [
        "Implement a convolutional neural network for image classification on CIFAR-10 dataset.\n",
        "\n",
        "CIFAR-10 is an image dataset of 10 categories. Each image has a size of 32x32 pixels. The following code will download the dataset, and split it into `train` and `test`. For this question, we use the default validation split generated by Skorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQxOUQ29BuMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "310efd92386a4757a767d5204b08a865",
            "8346dadd8dcd437f9d0c73a8e86d4503",
            "87cad6ba7ef84d03a7f8c0cb37ec01ec",
            "b712d5d1ba464a378c00dbb2aec6dd8c",
            "0f3b4a3b037d47cb8ba1196d7dbd3b98",
            "3f3ef2c146bf4dd38424170b3090b055",
            "adbb9a799ba44a91b927b44d0c27e6d1",
            "44a89539615b4132a01ca7f5223ca281"
          ]
        },
        "outputId": "fe539e24-4cd1-42ef-8bda-9ec1a0accd54"
      },
      "source": [
        "train = torchvision.datasets.CIFAR10(\"./data\", train=True, download=True)\n",
        "test = torchvision.datasets.CIFAR10(\"./data\", train=False, download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "310efd92386a4757a767d5204b08a865",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieBpiwMwi6wD",
        "colab_type": "text"
      },
      "source": [
        "The following code visualizes some samples in the dataset. You may use it to debug your model if necessary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5HrxybupyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "c9568768-b950-40b7-c16a-9d21a0969075"
      },
      "source": [
        "def plot(data, labels=None, num_sample=5):\n",
        "  n = min(len(data), num_sample)\n",
        "  for i in range(n):\n",
        "    plt.subplot(1, n, i+1)\n",
        "    plt.imshow(data[i], cmap=\"gray\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    if labels is not None:\n",
        "      plt.title(labels[i])\n",
        "\n",
        "train.labels = [train.classes[target] for target in train.targets]\n",
        "plot(train.data, train.labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWUAAABbCAYAAACrgpTSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncmaZZZbZPrJsUM4ss8wy20f2/wObcV05GGeeKQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwzKmdcuCv1D",
        "colab_type": "text"
      },
      "source": [
        "### 1) Basic CNN implementation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbEYo5WgjTtm",
        "colab_type": "text"
      },
      "source": [
        "Consider a basic CNN model\n",
        "\n",
        "- It has 3 convolutional layers, followed by a linear layer.\n",
        "- Each convolutional layer has a kernel size of 3, a padding of 1.\n",
        "- ReLU activation is applied on every hidden layer.\n",
        "\n",
        "Please implement this model in the following section. You will need to tune the hyperparameters and fill the results in the table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKyE2GUfL-Z",
        "colab_type": "text"
      },
      "source": [
        "#### a) Implement convolutional layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P_aYytExtq9",
        "colab_type": "text"
      },
      "source": [
        "Implement the initialization function and the forward function of the CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDmCKUD1LBFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,channels,3,padding=1)\n",
        "    self.conv2 = nn.Conv2d(channels,channels,3,padding=1)\n",
        "    self.conv3 = nn.Conv2d(channels,channels,3,padding=1)\n",
        "    self.fc1 = nn.Linear(channels*32*32,10)\n",
        "  \n",
        "  def forward(self, images):\n",
        "    images = images.float()\n",
        "    images = F.relu(self.conv1(images))\n",
        "    images = F.relu(self.conv2(images))\n",
        "    images = F.relu(self.conv3(images))\n",
        "    images = images.view(images.size(0), -1)\n",
        "    images = self.fc1(images)\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_YaASPpgRiL",
        "colab_type": "text"
      },
      "source": [
        "#### b) Tune hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygMcDdpy6XWP",
        "colab_type": "text"
      },
      "source": [
        "Train the CNN model on CIFAR-10 dataset. Tune the number of channels, optimizer, learning rate and the number of epochs for best validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUaguxFA5xOp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e74d78b8-10c0-414a-93d4-128f8ca4b2fd"
      },
      "source": [
        "# implement hyperparameters here\n",
        "\n",
        "learning_rate = [1e-5, 1e-4, 1e-3, 1e-2]\n",
        "optimize = [torch.optim.SGD, torch.optim.Adam]\n",
        "channel = [128, 256, 512]\n",
        "\n",
        "\n",
        "train_data_normalized = torch.Tensor(train.data/255)\n",
        "train_data_normalized = train_data_normalized.permute(0,3,1,2)\n",
        "\n",
        "for l in learning_rate:\n",
        "  for o in optimize: \n",
        "    for c in channel:\n",
        "      print(f'The channel was {c}, the learning rate was {l} and the optimizer was {str(o)}')\n",
        "\n",
        "      cnn = CNN(channels = c)\n",
        "      \n",
        "      model = skorch.NeuralNetClassifier(cnn, criterion=torch.nn.CrossEntropyLoss,\n",
        "                                   device=\"cuda\",\n",
        "                                   optimizer=o,\n",
        "                                  # optimizer__momentum=0.90,\n",
        "                                   lr=l,\n",
        "                                   max_epochs=25,\n",
        "                                   batch_size=64,\n",
        "                                   callbacks=[skorch.callbacks.EarlyStopping(lower_is_better=True)])\n",
        "      # implement input normalization & type cast here \n",
        "      model.fit(train_data_normalized, np.asarray(train.targets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The channel was 128, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.3032\u001b[0m       \u001b[32m0.0999\u001b[0m        \u001b[35m2.3027\u001b[0m  18.5060\n",
            "      2        \u001b[36m2.3021\u001b[0m       0.0990        \u001b[35m2.3016\u001b[0m  18.4268\n",
            "      3        \u001b[36m2.3010\u001b[0m       \u001b[32m0.1131\u001b[0m        \u001b[35m2.3005\u001b[0m  18.4448\n",
            "      4        \u001b[36m2.3000\u001b[0m       \u001b[32m0.1135\u001b[0m        \u001b[35m2.2995\u001b[0m  18.4798\n",
            "      5        \u001b[36m2.2990\u001b[0m       0.1079        \u001b[35m2.2985\u001b[0m  18.4404\n",
            "      6        \u001b[36m2.2981\u001b[0m       0.1052        \u001b[35m2.2975\u001b[0m  18.4569\n",
            "      7        \u001b[36m2.2971\u001b[0m       0.1037        \u001b[35m2.2965\u001b[0m  18.4508\n",
            "      8        \u001b[36m2.2961\u001b[0m       0.1036        \u001b[35m2.2956\u001b[0m  18.4712\n",
            "      9        \u001b[36m2.2952\u001b[0m       0.1029        \u001b[35m2.2946\u001b[0m  18.4494\n",
            "     10        \u001b[36m2.2942\u001b[0m       0.1029        \u001b[35m2.2936\u001b[0m  18.4175\n",
            "     11        \u001b[36m2.2933\u001b[0m       0.1035        \u001b[35m2.2926\u001b[0m  18.4708\n",
            "     12        \u001b[36m2.2923\u001b[0m       0.1039        \u001b[35m2.2916\u001b[0m  18.4207\n",
            "     13        \u001b[36m2.2913\u001b[0m       0.1053        \u001b[35m2.2906\u001b[0m  18.4349\n",
            "     14        \u001b[36m2.2903\u001b[0m       0.1067        \u001b[35m2.2895\u001b[0m  18.4755\n",
            "     15        \u001b[36m2.2893\u001b[0m       0.1078        \u001b[35m2.2884\u001b[0m  18.4174\n",
            "     16        \u001b[36m2.2882\u001b[0m       0.1100        \u001b[35m2.2874\u001b[0m  18.3775\n",
            "     17        \u001b[36m2.2871\u001b[0m       0.1119        \u001b[35m2.2862\u001b[0m  18.2645\n",
            "     18        \u001b[36m2.2860\u001b[0m       0.1134        \u001b[35m2.2851\u001b[0m  18.2422\n",
            "     19        \u001b[36m2.2849\u001b[0m       \u001b[32m0.1145\u001b[0m        \u001b[35m2.2839\u001b[0m  18.2590\n",
            "     20        \u001b[36m2.2837\u001b[0m       \u001b[32m0.1153\u001b[0m        \u001b[35m2.2827\u001b[0m  18.2531\n",
            "     21        \u001b[36m2.2825\u001b[0m       \u001b[32m0.1189\u001b[0m        \u001b[35m2.2815\u001b[0m  18.2642\n",
            "     22        \u001b[36m2.2813\u001b[0m       \u001b[32m0.1224\u001b[0m        \u001b[35m2.2802\u001b[0m  18.2686\n",
            "     23        \u001b[36m2.2801\u001b[0m       \u001b[32m0.1262\u001b[0m        \u001b[35m2.2789\u001b[0m  18.2649\n",
            "     24        \u001b[36m2.2787\u001b[0m       \u001b[32m0.1293\u001b[0m        \u001b[35m2.2775\u001b[0m  18.2677\n",
            "     25        \u001b[36m2.2774\u001b[0m       \u001b[32m0.1337\u001b[0m        \u001b[35m2.2761\u001b[0m  18.2547\n",
            "The channel was 256, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.3016\u001b[0m       \u001b[32m0.1130\u001b[0m        \u001b[35m2.3007\u001b[0m  28.1561\n",
            "      2        \u001b[36m2.3000\u001b[0m       0.1012        \u001b[35m2.2991\u001b[0m  28.1751\n",
            "      3        \u001b[36m2.2984\u001b[0m       0.1001        \u001b[35m2.2976\u001b[0m  28.1716\n",
            "      4        \u001b[36m2.2970\u001b[0m       0.0999        \u001b[35m2.2961\u001b[0m  28.2134\n",
            "      5        \u001b[36m2.2956\u001b[0m       0.0999        \u001b[35m2.2947\u001b[0m  28.2421\n",
            "      6        \u001b[36m2.2942\u001b[0m       0.0999        \u001b[35m2.2933\u001b[0m  28.2737\n",
            "      7        \u001b[36m2.2929\u001b[0m       0.1001        \u001b[35m2.2919\u001b[0m  28.2773\n",
            "      8        \u001b[36m2.2915\u001b[0m       0.1000        \u001b[35m2.2905\u001b[0m  28.2691\n",
            "      9        \u001b[36m2.2901\u001b[0m       0.1001        \u001b[35m2.2891\u001b[0m  28.3177\n",
            "     10        \u001b[36m2.2888\u001b[0m       0.1009        \u001b[35m2.2877\u001b[0m  28.3341\n",
            "     11        \u001b[36m2.2874\u001b[0m       0.1015        \u001b[35m2.2863\u001b[0m  28.3730\n",
            "     12        \u001b[36m2.2859\u001b[0m       0.1036        \u001b[35m2.2848\u001b[0m  28.3956\n",
            "     13        \u001b[36m2.2845\u001b[0m       0.1050        \u001b[35m2.2833\u001b[0m  28.3668\n",
            "     14        \u001b[36m2.2830\u001b[0m       0.1064        \u001b[35m2.2817\u001b[0m  28.3812\n",
            "     15        \u001b[36m2.2814\u001b[0m       0.1090        \u001b[35m2.2802\u001b[0m  28.3518\n",
            "     16        \u001b[36m2.2799\u001b[0m       0.1114        \u001b[35m2.2785\u001b[0m  28.3212\n",
            "     17        \u001b[36m2.2782\u001b[0m       \u001b[32m0.1138\u001b[0m        \u001b[35m2.2768\u001b[0m  28.2822\n",
            "     18        \u001b[36m2.2766\u001b[0m       \u001b[32m0.1184\u001b[0m        \u001b[35m2.2751\u001b[0m  28.2366\n",
            "     19        \u001b[36m2.2748\u001b[0m       \u001b[32m0.1226\u001b[0m        \u001b[35m2.2733\u001b[0m  28.2122\n",
            "     20        \u001b[36m2.2731\u001b[0m       \u001b[32m0.1268\u001b[0m        \u001b[35m2.2715\u001b[0m  28.1662\n",
            "     21        \u001b[36m2.2712\u001b[0m       \u001b[32m0.1308\u001b[0m        \u001b[35m2.2696\u001b[0m  28.2068\n",
            "     22        \u001b[36m2.2693\u001b[0m       \u001b[32m0.1355\u001b[0m        \u001b[35m2.2676\u001b[0m  28.1768\n",
            "     23        \u001b[36m2.2673\u001b[0m       \u001b[32m0.1406\u001b[0m        \u001b[35m2.2655\u001b[0m  28.2106\n",
            "     24        \u001b[36m2.2653\u001b[0m       \u001b[32m0.1455\u001b[0m        \u001b[35m2.2634\u001b[0m  28.1854\n",
            "     25        \u001b[36m2.2632\u001b[0m       \u001b[32m0.1502\u001b[0m        \u001b[35m2.2612\u001b[0m  28.1844\n",
            "The channel was 512, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.3002\u001b[0m       \u001b[32m0.1110\u001b[0m        \u001b[35m2.2977\u001b[0m  84.4267\n",
            "      2        \u001b[36m2.2957\u001b[0m       0.1008        \u001b[35m2.2936\u001b[0m  84.5223\n",
            "      3        \u001b[36m2.2919\u001b[0m       0.1024        \u001b[35m2.2898\u001b[0m  84.4769\n",
            "      4        \u001b[36m2.2883\u001b[0m       0.1046        \u001b[35m2.2862\u001b[0m  84.4598\n",
            "      5        \u001b[36m2.2848\u001b[0m       0.1109        \u001b[35m2.2825\u001b[0m  84.4638\n",
            "      6        \u001b[36m2.2812\u001b[0m       \u001b[32m0.1179\u001b[0m        \u001b[35m2.2789\u001b[0m  84.4542\n",
            "      7        \u001b[36m2.2775\u001b[0m       \u001b[32m0.1275\u001b[0m        \u001b[35m2.2751\u001b[0m  84.4658\n",
            "      8        \u001b[36m2.2738\u001b[0m       \u001b[32m0.1393\u001b[0m        \u001b[35m2.2711\u001b[0m  84.4803\n",
            "      9        \u001b[36m2.2698\u001b[0m       \u001b[32m0.1506\u001b[0m        \u001b[35m2.2671\u001b[0m  84.4830\n",
            "     10        \u001b[36m2.2658\u001b[0m       \u001b[32m0.1587\u001b[0m        \u001b[35m2.2628\u001b[0m  84.4822\n",
            "     11        \u001b[36m2.2615\u001b[0m       \u001b[32m0.1687\u001b[0m        \u001b[35m2.2584\u001b[0m  84.4412\n",
            "     12        \u001b[36m2.2571\u001b[0m       \u001b[32m0.1769\u001b[0m        \u001b[35m2.2538\u001b[0m  84.4710\n",
            "     13        \u001b[36m2.2525\u001b[0m       \u001b[32m0.1852\u001b[0m        \u001b[35m2.2490\u001b[0m  84.4580\n",
            "     14        \u001b[36m2.2477\u001b[0m       \u001b[32m0.1936\u001b[0m        \u001b[35m2.2440\u001b[0m  84.6451\n",
            "     15        \u001b[36m2.2427\u001b[0m       \u001b[32m0.1985\u001b[0m        \u001b[35m2.2388\u001b[0m  84.7819\n",
            "     16        \u001b[36m2.2374\u001b[0m       \u001b[32m0.2044\u001b[0m        \u001b[35m2.2333\u001b[0m  84.7537\n",
            "     17        \u001b[36m2.2320\u001b[0m       \u001b[32m0.2104\u001b[0m        \u001b[35m2.2277\u001b[0m  84.7516\n",
            "     18        \u001b[36m2.2263\u001b[0m       \u001b[32m0.2158\u001b[0m        \u001b[35m2.2218\u001b[0m  84.7166\n",
            "     19        \u001b[36m2.2204\u001b[0m       \u001b[32m0.2192\u001b[0m        \u001b[35m2.2157\u001b[0m  84.4826\n",
            "     20        \u001b[36m2.2143\u001b[0m       \u001b[32m0.2252\u001b[0m        \u001b[35m2.2094\u001b[0m  84.4852\n",
            "     21        \u001b[36m2.2081\u001b[0m       \u001b[32m0.2292\u001b[0m        \u001b[35m2.2029\u001b[0m  84.4808\n",
            "     22        \u001b[36m2.2016\u001b[0m       \u001b[32m0.2323\u001b[0m        \u001b[35m2.1963\u001b[0m  84.4748\n",
            "     23        \u001b[36m2.1950\u001b[0m       \u001b[32m0.2344\u001b[0m        \u001b[35m2.1895\u001b[0m  84.4671\n",
            "     24        \u001b[36m2.1883\u001b[0m       \u001b[32m0.2370\u001b[0m        \u001b[35m2.1826\u001b[0m  84.4871\n",
            "     25        \u001b[36m2.1814\u001b[0m       \u001b[32m0.2383\u001b[0m        \u001b[35m2.1755\u001b[0m  84.5190\n",
            "The channel was 128, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.9211\u001b[0m       \u001b[32m0.4091\u001b[0m        \u001b[35m1.7102\u001b[0m  18.5672\n",
            "      2        \u001b[36m1.6400\u001b[0m       \u001b[32m0.4547\u001b[0m        \u001b[35m1.5690\u001b[0m  18.5698\n",
            "      3        \u001b[36m1.5328\u001b[0m       \u001b[32m0.4792\u001b[0m        \u001b[35m1.4923\u001b[0m  18.5822\n",
            "      4        \u001b[36m1.4637\u001b[0m       \u001b[32m0.4940\u001b[0m        \u001b[35m1.4388\u001b[0m  18.5670\n",
            "      5        \u001b[36m1.4096\u001b[0m       \u001b[32m0.5082\u001b[0m        \u001b[35m1.3964\u001b[0m  18.5934\n",
            "      6        \u001b[36m1.3642\u001b[0m       \u001b[32m0.5203\u001b[0m        \u001b[35m1.3599\u001b[0m  18.5760\n",
            "      7        \u001b[36m1.3239\u001b[0m       \u001b[32m0.5318\u001b[0m        \u001b[35m1.3283\u001b[0m  18.5717\n",
            "      8        \u001b[36m1.2890\u001b[0m       \u001b[32m0.5427\u001b[0m        \u001b[35m1.3017\u001b[0m  18.5839\n",
            "      9        \u001b[36m1.2595\u001b[0m       \u001b[32m0.5512\u001b[0m        \u001b[35m1.2799\u001b[0m  18.5780\n",
            "     10        \u001b[36m1.2343\u001b[0m       \u001b[32m0.5576\u001b[0m        \u001b[35m1.2617\u001b[0m  18.5645\n",
            "     11        \u001b[36m1.2124\u001b[0m       \u001b[32m0.5611\u001b[0m        \u001b[35m1.2464\u001b[0m  18.5733\n",
            "     12        \u001b[36m1.1928\u001b[0m       \u001b[32m0.5657\u001b[0m        \u001b[35m1.2331\u001b[0m  18.5562\n",
            "     13        \u001b[36m1.1748\u001b[0m       \u001b[32m0.5696\u001b[0m        \u001b[35m1.2214\u001b[0m  18.6119\n",
            "     14        \u001b[36m1.1580\u001b[0m       \u001b[32m0.5726\u001b[0m        \u001b[35m1.2107\u001b[0m  18.6095\n",
            "     15        \u001b[36m1.1421\u001b[0m       \u001b[32m0.5765\u001b[0m        \u001b[35m1.2009\u001b[0m  18.5742\n",
            "     16        \u001b[36m1.1268\u001b[0m       \u001b[32m0.5802\u001b[0m        \u001b[35m1.1917\u001b[0m  18.5939\n",
            "     17        \u001b[36m1.1122\u001b[0m       \u001b[32m0.5828\u001b[0m        \u001b[35m1.1829\u001b[0m  18.5858\n",
            "     18        \u001b[36m1.0980\u001b[0m       \u001b[32m0.5845\u001b[0m        \u001b[35m1.1747\u001b[0m  18.5785\n",
            "     19        \u001b[36m1.0843\u001b[0m       \u001b[32m0.5875\u001b[0m        \u001b[35m1.1668\u001b[0m  18.6000\n",
            "     20        \u001b[36m1.0709\u001b[0m       \u001b[32m0.5895\u001b[0m        \u001b[35m1.1593\u001b[0m  18.5876\n",
            "     21        \u001b[36m1.0577\u001b[0m       \u001b[32m0.5927\u001b[0m        \u001b[35m1.1521\u001b[0m  18.5913\n",
            "     22        \u001b[36m1.0448\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m1.1451\u001b[0m  18.5922\n",
            "     23        \u001b[36m1.0321\u001b[0m       \u001b[32m0.5995\u001b[0m        \u001b[35m1.1384\u001b[0m  18.5667\n",
            "     24        \u001b[36m1.0197\u001b[0m       \u001b[32m0.6018\u001b[0m        \u001b[35m1.1319\u001b[0m  18.5899\n",
            "     25        \u001b[36m1.0074\u001b[0m       \u001b[32m0.6040\u001b[0m        \u001b[35m1.1257\u001b[0m  18.5958\n",
            "The channel was 256, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.7993\u001b[0m       \u001b[32m0.4549\u001b[0m        \u001b[35m1.5443\u001b[0m  28.6724\n",
            "      2        \u001b[36m1.4878\u001b[0m       \u001b[32m0.5016\u001b[0m        \u001b[35m1.4192\u001b[0m  28.6872\n",
            "      3        \u001b[36m1.3693\u001b[0m       \u001b[32m0.5282\u001b[0m        \u001b[35m1.3407\u001b[0m  28.7155\n",
            "      4        \u001b[36m1.2880\u001b[0m       \u001b[32m0.5487\u001b[0m        \u001b[35m1.2815\u001b[0m  28.6695\n",
            "      5        \u001b[36m1.2337\u001b[0m       \u001b[32m0.5612\u001b[0m        \u001b[35m1.2469\u001b[0m  28.7108\n",
            "      6        \u001b[36m1.1921\u001b[0m       \u001b[32m0.5688\u001b[0m        \u001b[35m1.2231\u001b[0m  28.6816\n",
            "      7        \u001b[36m1.1568\u001b[0m       \u001b[32m0.5742\u001b[0m        \u001b[35m1.2045\u001b[0m  28.6880\n",
            "      8        \u001b[36m1.1248\u001b[0m       \u001b[32m0.5817\u001b[0m        \u001b[35m1.1868\u001b[0m  28.6945\n",
            "      9        \u001b[36m1.0947\u001b[0m       \u001b[32m0.5866\u001b[0m        \u001b[35m1.1700\u001b[0m  28.6868\n",
            "     10        \u001b[36m1.0657\u001b[0m       \u001b[32m0.5932\u001b[0m        \u001b[35m1.1532\u001b[0m  28.6938\n",
            "     11        \u001b[36m1.0378\u001b[0m       \u001b[32m0.6002\u001b[0m        \u001b[35m1.1368\u001b[0m  28.6730\n",
            "     12        \u001b[36m1.0106\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m1.1208\u001b[0m  28.6910\n",
            "     13        \u001b[36m0.9843\u001b[0m       \u001b[32m0.6136\u001b[0m        \u001b[35m1.1053\u001b[0m  28.6957\n",
            "     14        \u001b[36m0.9588\u001b[0m       \u001b[32m0.6177\u001b[0m        \u001b[35m1.0910\u001b[0m  28.7256\n",
            "     15        \u001b[36m0.9341\u001b[0m       \u001b[32m0.6214\u001b[0m        \u001b[35m1.0777\u001b[0m  28.8733\n",
            "     16        \u001b[36m0.9102\u001b[0m       \u001b[32m0.6246\u001b[0m        \u001b[35m1.0655\u001b[0m  28.9166\n",
            "     17        \u001b[36m0.8872\u001b[0m       \u001b[32m0.6275\u001b[0m        \u001b[35m1.0551\u001b[0m  28.9457\n",
            "     18        \u001b[36m0.8650\u001b[0m       \u001b[32m0.6298\u001b[0m        \u001b[35m1.0458\u001b[0m  28.9299\n",
            "     19        \u001b[36m0.8435\u001b[0m       \u001b[32m0.6339\u001b[0m        \u001b[35m1.0380\u001b[0m  28.9417\n",
            "     20        \u001b[36m0.8227\u001b[0m       \u001b[32m0.6362\u001b[0m        \u001b[35m1.0314\u001b[0m  28.9311\n",
            "     21        \u001b[36m0.8026\u001b[0m       \u001b[32m0.6376\u001b[0m        \u001b[35m1.0260\u001b[0m  28.8804\n",
            "     22        \u001b[36m0.7831\u001b[0m       \u001b[32m0.6390\u001b[0m        \u001b[35m1.0219\u001b[0m  28.8926\n",
            "     23        \u001b[36m0.7642\u001b[0m       \u001b[32m0.6439\u001b[0m        \u001b[35m1.0189\u001b[0m  28.9216\n",
            "     24        \u001b[36m0.7458\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.0168\u001b[0m  28.9813\n",
            "     25        \u001b[36m0.7279\u001b[0m       \u001b[32m0.6489\u001b[0m        \u001b[35m1.0159\u001b[0m  28.9168\n",
            "The channel was 512, the learning rate was 1e-05 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.7052\u001b[0m       \u001b[32m0.4885\u001b[0m        \u001b[35m1.4554\u001b[0m  85.6192\n",
            "      2        \u001b[36m1.3678\u001b[0m       \u001b[32m0.5463\u001b[0m        \u001b[35m1.2847\u001b[0m  85.4737\n",
            "      3        \u001b[36m1.2379\u001b[0m       \u001b[32m0.5701\u001b[0m        \u001b[35m1.2226\u001b[0m  85.5098\n",
            "      4        \u001b[36m1.1589\u001b[0m       \u001b[32m0.5851\u001b[0m        \u001b[35m1.1813\u001b[0m  85.4974\n",
            "      5        \u001b[36m1.0900\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.1385\u001b[0m  85.5047\n",
            "      6        \u001b[36m1.0254\u001b[0m       \u001b[32m0.6127\u001b[0m        \u001b[35m1.1017\u001b[0m  85.5046\n",
            "      7        \u001b[36m0.9664\u001b[0m       \u001b[32m0.6223\u001b[0m        \u001b[35m1.0735\u001b[0m  85.5250\n",
            "      8        \u001b[36m0.9133\u001b[0m       \u001b[32m0.6270\u001b[0m        \u001b[35m1.0527\u001b[0m  85.5593\n",
            "      9        \u001b[36m0.8650\u001b[0m       \u001b[32m0.6365\u001b[0m        \u001b[35m1.0373\u001b[0m  85.5200\n",
            "     10        \u001b[36m0.8202\u001b[0m       \u001b[32m0.6408\u001b[0m        \u001b[35m1.0249\u001b[0m  85.5178\n",
            "     11        \u001b[36m0.7777\u001b[0m       \u001b[32m0.6479\u001b[0m        \u001b[35m1.0152\u001b[0m  85.5486\n",
            "     12        \u001b[36m0.7373\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.0096\u001b[0m  85.5278\n",
            "     13        \u001b[36m0.6987\u001b[0m       \u001b[32m0.6564\u001b[0m        \u001b[35m1.0078\u001b[0m  85.5311\n",
            "     14        \u001b[36m0.6616\u001b[0m       \u001b[32m0.6585\u001b[0m        1.0103  85.5342\n",
            "     15        \u001b[36m0.6255\u001b[0m       \u001b[32m0.6604\u001b[0m        1.0165  85.5549\n",
            "     16        \u001b[36m0.5903\u001b[0m       \u001b[32m0.6609\u001b[0m        1.0261  85.5722\n",
            "     17        \u001b[36m0.5557\u001b[0m       \u001b[32m0.6612\u001b[0m        1.0398  85.6411\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 128, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.2946\u001b[0m       \u001b[32m0.1078\u001b[0m        \u001b[35m2.2872\u001b[0m  18.6250\n",
            "      2        \u001b[36m2.2810\u001b[0m       \u001b[32m0.1357\u001b[0m        \u001b[35m2.2725\u001b[0m  18.6090\n",
            "      3        \u001b[36m2.2648\u001b[0m       \u001b[32m0.1722\u001b[0m        \u001b[35m2.2539\u001b[0m  18.5985\n",
            "      4        \u001b[36m2.2438\u001b[0m       \u001b[32m0.2012\u001b[0m        \u001b[35m2.2293\u001b[0m  18.5798\n",
            "      5        \u001b[36m2.2162\u001b[0m       \u001b[32m0.2194\u001b[0m        \u001b[35m2.1976\u001b[0m  18.5733\n",
            "      6        \u001b[36m2.1821\u001b[0m       \u001b[32m0.2320\u001b[0m        \u001b[35m2.1604\u001b[0m  18.5839\n",
            "      7        \u001b[36m2.1444\u001b[0m       \u001b[32m0.2482\u001b[0m        \u001b[35m2.1219\u001b[0m  18.6231\n",
            "      8        \u001b[36m2.1075\u001b[0m       \u001b[32m0.2650\u001b[0m        \u001b[35m2.0859\u001b[0m  18.6000\n",
            "      9        \u001b[36m2.0734\u001b[0m       \u001b[32m0.2778\u001b[0m        \u001b[35m2.0531\u001b[0m  18.6127\n",
            "     10        \u001b[36m2.0420\u001b[0m       \u001b[32m0.2885\u001b[0m        \u001b[35m2.0227\u001b[0m  18.5521\n",
            "     11        \u001b[36m2.0129\u001b[0m       \u001b[32m0.2982\u001b[0m        \u001b[35m1.9946\u001b[0m  18.5650\n",
            "     12        \u001b[36m1.9867\u001b[0m       \u001b[32m0.3080\u001b[0m        \u001b[35m1.9698\u001b[0m  18.5106\n",
            "     13        \u001b[36m1.9641\u001b[0m       \u001b[32m0.3178\u001b[0m        \u001b[35m1.9489\u001b[0m  18.4998\n",
            "     14        \u001b[36m1.9453\u001b[0m       \u001b[32m0.3233\u001b[0m        \u001b[35m1.9317\u001b[0m  18.4606\n",
            "     15        \u001b[36m1.9300\u001b[0m       \u001b[32m0.3290\u001b[0m        \u001b[35m1.9175\u001b[0m  18.3906\n",
            "     16        \u001b[36m1.9173\u001b[0m       \u001b[32m0.3340\u001b[0m        \u001b[35m1.9056\u001b[0m  18.4138\n",
            "     17        \u001b[36m1.9065\u001b[0m       \u001b[32m0.3381\u001b[0m        \u001b[35m1.8954\u001b[0m  18.3684\n",
            "     18        \u001b[36m1.8971\u001b[0m       \u001b[32m0.3400\u001b[0m        \u001b[35m1.8865\u001b[0m  18.3590\n",
            "     19        \u001b[36m1.8887\u001b[0m       \u001b[32m0.3420\u001b[0m        \u001b[35m1.8784\u001b[0m  18.3709\n",
            "     20        \u001b[36m1.8811\u001b[0m       \u001b[32m0.3451\u001b[0m        \u001b[35m1.8709\u001b[0m  18.3542\n",
            "     21        \u001b[36m1.8741\u001b[0m       \u001b[32m0.3482\u001b[0m        \u001b[35m1.8641\u001b[0m  18.3616\n",
            "     22        \u001b[36m1.8675\u001b[0m       \u001b[32m0.3511\u001b[0m        \u001b[35m1.8576\u001b[0m  18.3801\n",
            "     23        \u001b[36m1.8613\u001b[0m       \u001b[32m0.3526\u001b[0m        \u001b[35m1.8515\u001b[0m  18.3824\n",
            "     24        \u001b[36m1.8555\u001b[0m       \u001b[32m0.3554\u001b[0m        \u001b[35m1.8457\u001b[0m  18.3563\n",
            "     25        \u001b[36m1.8498\u001b[0m       \u001b[32m0.3590\u001b[0m        \u001b[35m1.8401\u001b[0m  18.3585\n",
            "The channel was 256, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.2948\u001b[0m       \u001b[32m0.1034\u001b[0m        \u001b[35m2.2850\u001b[0m  28.2140\n",
            "      2        \u001b[36m2.2757\u001b[0m       \u001b[32m0.1418\u001b[0m        \u001b[35m2.2638\u001b[0m  28.2355\n",
            "      3        \u001b[36m2.2509\u001b[0m       \u001b[32m0.1931\u001b[0m        \u001b[35m2.2336\u001b[0m  28.2157\n",
            "      4        \u001b[36m2.2157\u001b[0m       \u001b[32m0.2249\u001b[0m        \u001b[35m2.1920\u001b[0m  28.2257\n",
            "      5        \u001b[36m2.1701\u001b[0m       \u001b[32m0.2437\u001b[0m        \u001b[35m2.1421\u001b[0m  28.2625\n",
            "      6        \u001b[36m2.1201\u001b[0m       \u001b[32m0.2623\u001b[0m        \u001b[35m2.0921\u001b[0m  28.2397\n",
            "      7        \u001b[36m2.0729\u001b[0m       \u001b[32m0.2792\u001b[0m        \u001b[35m2.0472\u001b[0m  28.2208\n",
            "      8        \u001b[36m2.0309\u001b[0m       \u001b[32m0.2954\u001b[0m        \u001b[35m2.0074\u001b[0m  28.2211\n",
            "      9        \u001b[36m1.9941\u001b[0m       \u001b[32m0.3102\u001b[0m        \u001b[35m1.9731\u001b[0m  28.2339\n",
            "     10        \u001b[36m1.9632\u001b[0m       \u001b[32m0.3198\u001b[0m        \u001b[35m1.9450\u001b[0m  28.2379\n",
            "     11        \u001b[36m1.9387\u001b[0m       \u001b[32m0.3278\u001b[0m        \u001b[35m1.9229\u001b[0m  28.2316\n",
            "     12        \u001b[36m1.9194\u001b[0m       \u001b[32m0.3319\u001b[0m        \u001b[35m1.9055\u001b[0m  28.2354\n",
            "     13        \u001b[36m1.9040\u001b[0m       \u001b[32m0.3374\u001b[0m        \u001b[35m1.8913\u001b[0m  28.2233\n",
            "     14        \u001b[36m1.8912\u001b[0m       \u001b[32m0.3422\u001b[0m        \u001b[35m1.8793\u001b[0m  28.2371\n",
            "     15        \u001b[36m1.8801\u001b[0m       \u001b[32m0.3465\u001b[0m        \u001b[35m1.8687\u001b[0m  28.2421\n",
            "     16        \u001b[36m1.8703\u001b[0m       \u001b[32m0.3506\u001b[0m        \u001b[35m1.8592\u001b[0m  28.2473\n",
            "     17        \u001b[36m1.8613\u001b[0m       \u001b[32m0.3544\u001b[0m        \u001b[35m1.8505\u001b[0m  28.2365\n",
            "     18        \u001b[36m1.8530\u001b[0m       \u001b[32m0.3570\u001b[0m        \u001b[35m1.8424\u001b[0m  28.2540\n",
            "     19        \u001b[36m1.8453\u001b[0m       \u001b[32m0.3612\u001b[0m        \u001b[35m1.8348\u001b[0m  28.2420\n",
            "     20        \u001b[36m1.8379\u001b[0m       \u001b[32m0.3632\u001b[0m        \u001b[35m1.8276\u001b[0m  28.2478\n",
            "     21        \u001b[36m1.8309\u001b[0m       \u001b[32m0.3650\u001b[0m        \u001b[35m1.8208\u001b[0m  28.2357\n",
            "     22        \u001b[36m1.8242\u001b[0m       \u001b[32m0.3683\u001b[0m        \u001b[35m1.8142\u001b[0m  28.2210\n",
            "     23        \u001b[36m1.8177\u001b[0m       \u001b[32m0.3698\u001b[0m        \u001b[35m1.8077\u001b[0m  28.2471\n",
            "     24        \u001b[36m1.8113\u001b[0m       \u001b[32m0.3722\u001b[0m        \u001b[35m1.8015\u001b[0m  28.2639\n",
            "     25        \u001b[36m1.8050\u001b[0m       \u001b[32m0.3752\u001b[0m        \u001b[35m1.7953\u001b[0m  28.2459\n",
            "The channel was 512, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.2829\u001b[0m       \u001b[32m0.1567\u001b[0m        \u001b[35m2.2618\u001b[0m  84.4749\n",
            "      2        \u001b[36m2.2379\u001b[0m       \u001b[32m0.2252\u001b[0m        \u001b[35m2.2076\u001b[0m  84.4385\n",
            "      3        \u001b[36m2.1743\u001b[0m       \u001b[32m0.2600\u001b[0m        \u001b[35m2.1338\u001b[0m  84.4289\n",
            "      4        \u001b[36m2.0976\u001b[0m       \u001b[32m0.2849\u001b[0m        \u001b[35m2.0562\u001b[0m  84.4439\n",
            "      5        \u001b[36m2.0277\u001b[0m       \u001b[32m0.3013\u001b[0m        \u001b[35m1.9948\u001b[0m  84.4723\n",
            "      6        \u001b[36m1.9770\u001b[0m       \u001b[32m0.3138\u001b[0m        \u001b[35m1.9528\u001b[0m  84.5294\n",
            "      7        \u001b[36m1.9424\u001b[0m       \u001b[32m0.3231\u001b[0m        \u001b[35m1.9236\u001b[0m  84.7131\n",
            "      8        \u001b[36m1.9175\u001b[0m       \u001b[32m0.3311\u001b[0m        \u001b[35m1.9016\u001b[0m  84.7300\n",
            "      9        \u001b[36m1.8978\u001b[0m       \u001b[32m0.3397\u001b[0m        \u001b[35m1.8836\u001b[0m  84.7649\n",
            "     10        \u001b[36m1.8813\u001b[0m       \u001b[32m0.3468\u001b[0m        \u001b[35m1.8681\u001b[0m  84.6586\n",
            "     11        \u001b[36m1.8668\u001b[0m       \u001b[32m0.3520\u001b[0m        \u001b[35m1.8543\u001b[0m  84.4454\n",
            "     12        \u001b[36m1.8539\u001b[0m       \u001b[32m0.3569\u001b[0m        \u001b[35m1.8418\u001b[0m  84.4662\n",
            "     13        \u001b[36m1.8421\u001b[0m       \u001b[32m0.3621\u001b[0m        \u001b[35m1.8304\u001b[0m  84.4491\n",
            "     14        \u001b[36m1.8312\u001b[0m       \u001b[32m0.3664\u001b[0m        \u001b[35m1.8198\u001b[0m  84.4167\n",
            "     15        \u001b[36m1.8210\u001b[0m       \u001b[32m0.3705\u001b[0m        \u001b[35m1.8098\u001b[0m  84.4375\n",
            "     16        \u001b[36m1.8113\u001b[0m       \u001b[32m0.3738\u001b[0m        \u001b[35m1.8002\u001b[0m  84.4431\n",
            "     17        \u001b[36m1.8020\u001b[0m       \u001b[32m0.3769\u001b[0m        \u001b[35m1.7909\u001b[0m  84.4530\n",
            "     18        \u001b[36m1.7929\u001b[0m       \u001b[32m0.3807\u001b[0m        \u001b[35m1.7819\u001b[0m  84.4527\n",
            "     19        \u001b[36m1.7840\u001b[0m       \u001b[32m0.3839\u001b[0m        \u001b[35m1.7730\u001b[0m  84.4372\n",
            "     20        \u001b[36m1.7752\u001b[0m       \u001b[32m0.3870\u001b[0m        \u001b[35m1.7643\u001b[0m  84.4245\n",
            "     21        \u001b[36m1.7666\u001b[0m       \u001b[32m0.3918\u001b[0m        \u001b[35m1.7557\u001b[0m  84.4678\n",
            "     22        \u001b[36m1.7582\u001b[0m       \u001b[32m0.3942\u001b[0m        \u001b[35m1.7473\u001b[0m  84.4631\n",
            "     23        \u001b[36m1.7499\u001b[0m       \u001b[32m0.3989\u001b[0m        \u001b[35m1.7391\u001b[0m  84.4391\n",
            "     24        \u001b[36m1.7418\u001b[0m       \u001b[32m0.4021\u001b[0m        \u001b[35m1.7312\u001b[0m  84.4390\n",
            "     25        \u001b[36m1.7340\u001b[0m       \u001b[32m0.4045\u001b[0m        \u001b[35m1.7235\u001b[0m  84.4519\n",
            "The channel was 128, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.5989\u001b[0m       \u001b[32m0.5399\u001b[0m        \u001b[35m1.3087\u001b[0m  18.5703\n",
            "      2        \u001b[36m1.2317\u001b[0m       \u001b[32m0.5960\u001b[0m        \u001b[35m1.1703\u001b[0m  18.5622\n",
            "      3        \u001b[36m1.0529\u001b[0m       \u001b[32m0.6107\u001b[0m        \u001b[35m1.1277\u001b[0m  18.5834\n",
            "      4        \u001b[36m0.9170\u001b[0m       \u001b[32m0.6341\u001b[0m        \u001b[35m1.0762\u001b[0m  18.5937\n",
            "      5        \u001b[36m0.8038\u001b[0m       \u001b[32m0.6511\u001b[0m        \u001b[35m1.0423\u001b[0m  18.5841\n",
            "      6        \u001b[36m0.7046\u001b[0m       \u001b[32m0.6591\u001b[0m        \u001b[35m1.0409\u001b[0m  18.6283\n",
            "      7        \u001b[36m0.6122\u001b[0m       0.6586        1.0729  18.5710\n",
            "      8        \u001b[36m0.5252\u001b[0m       0.6551        1.1254  18.5723\n",
            "      9        \u001b[36m0.4398\u001b[0m       0.6480        1.2132  18.5920\n",
            "     10        \u001b[36m0.3638\u001b[0m       0.6345        1.3543  18.5966\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 256, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.5557\u001b[0m       \u001b[32m0.5544\u001b[0m        \u001b[35m1.2657\u001b[0m  28.7303\n",
            "      2        \u001b[36m1.1919\u001b[0m       \u001b[32m0.6103\u001b[0m        \u001b[35m1.1134\u001b[0m  28.8635\n",
            "      3        \u001b[36m0.9954\u001b[0m       \u001b[32m0.6176\u001b[0m        \u001b[35m1.1032\u001b[0m  28.8710\n",
            "      4        \u001b[36m0.8200\u001b[0m       \u001b[32m0.6332\u001b[0m        \u001b[35m1.0971\u001b[0m  28.8569\n",
            "      5        \u001b[36m0.6662\u001b[0m       \u001b[32m0.6453\u001b[0m        1.1120  28.8684\n",
            "      6        \u001b[36m0.5218\u001b[0m       0.6443        1.1892  28.8009\n",
            "      7        \u001b[36m0.3892\u001b[0m       0.6417        1.3461  28.8497\n",
            "      8        \u001b[36m0.2984\u001b[0m       0.6261        1.5004  28.8000\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 512, the learning rate was 0.0001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.5351\u001b[0m       \u001b[32m0.5696\u001b[0m        \u001b[35m1.2304\u001b[0m  85.5676\n",
            "      2        \u001b[36m1.1298\u001b[0m       \u001b[32m0.6283\u001b[0m        \u001b[35m1.0654\u001b[0m  85.5023\n",
            "      3        \u001b[36m0.8948\u001b[0m       \u001b[32m0.6446\u001b[0m        \u001b[35m1.0556\u001b[0m  85.3184\n",
            "      4        \u001b[36m0.6956\u001b[0m       \u001b[32m0.6547\u001b[0m        1.0958  85.2917\n",
            "      5        \u001b[36m0.5090\u001b[0m       0.6459        1.2251  85.2944\n",
            "      6        \u001b[36m0.3517\u001b[0m       0.6389        1.4520  85.2887\n",
            "      7        \u001b[36m0.2626\u001b[0m       0.6257        1.6268  85.2929\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 128, the learning rate was 0.001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.2285\u001b[0m       \u001b[32m0.2720\u001b[0m        \u001b[35m2.0900\u001b[0m  18.3243\n",
            "      2        \u001b[36m1.9807\u001b[0m       \u001b[32m0.3243\u001b[0m        \u001b[35m1.9160\u001b[0m  18.3327\n",
            "      3        \u001b[36m1.8848\u001b[0m       \u001b[32m0.3479\u001b[0m        \u001b[35m1.8528\u001b[0m  18.3209\n",
            "      4        \u001b[36m1.8359\u001b[0m       \u001b[32m0.3649\u001b[0m        \u001b[35m1.8110\u001b[0m  18.3176\n",
            "      5        \u001b[36m1.7982\u001b[0m       \u001b[32m0.3766\u001b[0m        \u001b[35m1.7751\u001b[0m  18.3190\n",
            "      6        \u001b[36m1.7621\u001b[0m       \u001b[32m0.3902\u001b[0m        \u001b[35m1.7374\u001b[0m  18.3227\n",
            "      7        \u001b[36m1.7247\u001b[0m       \u001b[32m0.4066\u001b[0m        \u001b[35m1.6979\u001b[0m  18.3303\n",
            "      8        \u001b[36m1.6894\u001b[0m       \u001b[32m0.4195\u001b[0m        \u001b[35m1.6641\u001b[0m  18.3276\n",
            "      9        \u001b[36m1.6598\u001b[0m       \u001b[32m0.4295\u001b[0m        \u001b[35m1.6374\u001b[0m  18.3401\n",
            "     10        \u001b[36m1.6337\u001b[0m       \u001b[32m0.4390\u001b[0m        \u001b[35m1.6137\u001b[0m  18.3173\n",
            "     11        \u001b[36m1.6093\u001b[0m       \u001b[32m0.4461\u001b[0m        \u001b[35m1.5922\u001b[0m  18.3347\n",
            "     12        \u001b[36m1.5866\u001b[0m       \u001b[32m0.4520\u001b[0m        \u001b[35m1.5720\u001b[0m  18.3388\n",
            "     13        \u001b[36m1.5650\u001b[0m       \u001b[32m0.4574\u001b[0m        \u001b[35m1.5524\u001b[0m  18.3235\n",
            "     14        \u001b[36m1.5438\u001b[0m       \u001b[32m0.4628\u001b[0m        \u001b[35m1.5331\u001b[0m  18.3218\n",
            "     15        \u001b[36m1.5232\u001b[0m       \u001b[32m0.4679\u001b[0m        \u001b[35m1.5145\u001b[0m  18.3246\n",
            "     16        \u001b[36m1.5035\u001b[0m       \u001b[32m0.4752\u001b[0m        \u001b[35m1.4968\u001b[0m  18.3466\n",
            "     17        \u001b[36m1.4847\u001b[0m       \u001b[32m0.4776\u001b[0m        \u001b[35m1.4805\u001b[0m  18.3315\n",
            "     18        \u001b[36m1.4671\u001b[0m       \u001b[32m0.4838\u001b[0m        \u001b[35m1.4655\u001b[0m  18.3239\n",
            "     19        \u001b[36m1.4505\u001b[0m       \u001b[32m0.4847\u001b[0m        \u001b[35m1.4516\u001b[0m  18.3283\n",
            "     20        \u001b[36m1.4348\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m1.4386\u001b[0m  18.3192\n",
            "     21        \u001b[36m1.4195\u001b[0m       \u001b[32m0.4938\u001b[0m        \u001b[35m1.4264\u001b[0m  18.3331\n",
            "     22        \u001b[36m1.4045\u001b[0m       \u001b[32m0.4994\u001b[0m        \u001b[35m1.4147\u001b[0m  18.3225\n",
            "     23        \u001b[36m1.3896\u001b[0m       \u001b[32m0.5046\u001b[0m        \u001b[35m1.4033\u001b[0m  18.3101\n",
            "     24        \u001b[36m1.3745\u001b[0m       \u001b[32m0.5094\u001b[0m        \u001b[35m1.3919\u001b[0m  18.3177\n",
            "     25        \u001b[36m1.3592\u001b[0m       \u001b[32m0.5131\u001b[0m        \u001b[35m1.3808\u001b[0m  18.3429\n",
            "The channel was 256, the learning rate was 0.001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.1606\u001b[0m       \u001b[32m0.2928\u001b[0m        \u001b[35m1.9859\u001b[0m  28.1990\n",
            "      2        \u001b[36m1.9217\u001b[0m       \u001b[32m0.3448\u001b[0m        \u001b[35m1.8676\u001b[0m  28.2007\n",
            "      3        \u001b[36m1.8356\u001b[0m       \u001b[32m0.3732\u001b[0m        \u001b[35m1.7915\u001b[0m  28.2047\n",
            "      4        \u001b[36m1.7648\u001b[0m       \u001b[32m0.4005\u001b[0m        \u001b[35m1.7197\u001b[0m  28.1863\n",
            "      5        \u001b[36m1.7025\u001b[0m       \u001b[32m0.4187\u001b[0m        \u001b[35m1.6649\u001b[0m  28.1886\n",
            "      6        \u001b[36m1.6558\u001b[0m       \u001b[32m0.4347\u001b[0m        \u001b[35m1.6258\u001b[0m  28.2185\n",
            "      7        \u001b[36m1.6177\u001b[0m       \u001b[32m0.4470\u001b[0m        \u001b[35m1.5925\u001b[0m  28.2180\n",
            "      8        \u001b[36m1.5839\u001b[0m       \u001b[32m0.4581\u001b[0m        \u001b[35m1.5623\u001b[0m  28.2039\n",
            "      9        \u001b[36m1.5528\u001b[0m       \u001b[32m0.4628\u001b[0m        \u001b[35m1.5344\u001b[0m  28.1952\n",
            "     10        \u001b[36m1.5240\u001b[0m       \u001b[32m0.4691\u001b[0m        \u001b[35m1.5087\u001b[0m  28.1674\n",
            "     11        \u001b[36m1.4973\u001b[0m       \u001b[32m0.4770\u001b[0m        \u001b[35m1.4856\u001b[0m  28.1982\n",
            "     12        \u001b[36m1.4730\u001b[0m       \u001b[32m0.4834\u001b[0m        \u001b[35m1.4651\u001b[0m  28.1864\n",
            "     13        \u001b[36m1.4507\u001b[0m       \u001b[32m0.4905\u001b[0m        \u001b[35m1.4469\u001b[0m  28.2167\n",
            "     14        \u001b[36m1.4299\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.4301\u001b[0m  28.3516\n",
            "     15        \u001b[36m1.4100\u001b[0m       \u001b[32m0.5020\u001b[0m        \u001b[35m1.4143\u001b[0m  28.3319\n",
            "     16        \u001b[36m1.3906\u001b[0m       \u001b[32m0.5060\u001b[0m        \u001b[35m1.3991\u001b[0m  28.3447\n",
            "     17        \u001b[36m1.3713\u001b[0m       \u001b[32m0.5110\u001b[0m        \u001b[35m1.3844\u001b[0m  28.3431\n",
            "     18        \u001b[36m1.3520\u001b[0m       \u001b[32m0.5142\u001b[0m        \u001b[35m1.3699\u001b[0m  28.3198\n",
            "     19        \u001b[36m1.3327\u001b[0m       \u001b[32m0.5181\u001b[0m        \u001b[35m1.3556\u001b[0m  28.3126\n",
            "     20        \u001b[36m1.3139\u001b[0m       \u001b[32m0.5238\u001b[0m        \u001b[35m1.3421\u001b[0m  28.2719\n",
            "     21        \u001b[36m1.2959\u001b[0m       \u001b[32m0.5290\u001b[0m        \u001b[35m1.3289\u001b[0m  28.3117\n",
            "     22        \u001b[36m1.2790\u001b[0m       \u001b[32m0.5337\u001b[0m        \u001b[35m1.3159\u001b[0m  28.3427\n",
            "     23        \u001b[36m1.2633\u001b[0m       \u001b[32m0.5369\u001b[0m        \u001b[35m1.3036\u001b[0m  28.3535\n",
            "     24        \u001b[36m1.2488\u001b[0m       \u001b[32m0.5421\u001b[0m        \u001b[35m1.2920\u001b[0m  28.3192\n",
            "     25        \u001b[36m1.2353\u001b[0m       \u001b[32m0.5455\u001b[0m        \u001b[35m1.2807\u001b[0m  28.2492\n",
            "The channel was 512, the learning rate was 0.001 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.0927\u001b[0m       \u001b[32m0.3219\u001b[0m        \u001b[35m1.9257\u001b[0m  84.3446\n",
            "      2        \u001b[36m1.8728\u001b[0m       \u001b[32m0.3677\u001b[0m        \u001b[35m1.8156\u001b[0m  84.3199\n",
            "      3        \u001b[36m1.7801\u001b[0m       \u001b[32m0.3988\u001b[0m        \u001b[35m1.7256\u001b[0m  84.3312\n",
            "      4        \u001b[36m1.7034\u001b[0m       \u001b[32m0.4218\u001b[0m        \u001b[35m1.6600\u001b[0m  84.3438\n",
            "      5        \u001b[36m1.6479\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.6131\u001b[0m  84.3342\n",
            "      6        \u001b[36m1.6026\u001b[0m       \u001b[32m0.4512\u001b[0m        \u001b[35m1.5724\u001b[0m  84.3238\n",
            "      7        \u001b[36m1.5624\u001b[0m       \u001b[32m0.4624\u001b[0m        \u001b[35m1.5360\u001b[0m  84.3190\n",
            "      8        \u001b[36m1.5256\u001b[0m       \u001b[32m0.4738\u001b[0m        \u001b[35m1.5034\u001b[0m  84.3079\n",
            "      9        \u001b[36m1.4921\u001b[0m       \u001b[32m0.4822\u001b[0m        \u001b[35m1.4750\u001b[0m  84.3211\n",
            "     10        \u001b[36m1.4618\u001b[0m       \u001b[32m0.4887\u001b[0m        \u001b[35m1.4508\u001b[0m  84.3088\n",
            "     11        \u001b[36m1.4344\u001b[0m       \u001b[32m0.4968\u001b[0m        \u001b[35m1.4302\u001b[0m  84.3042\n",
            "     12        \u001b[36m1.4094\u001b[0m       \u001b[32m0.5021\u001b[0m        \u001b[35m1.4120\u001b[0m  84.3173\n",
            "     13        \u001b[36m1.3857\u001b[0m       \u001b[32m0.5063\u001b[0m        \u001b[35m1.3952\u001b[0m  84.3337\n",
            "     14        \u001b[36m1.3627\u001b[0m       \u001b[32m0.5098\u001b[0m        \u001b[35m1.3787\u001b[0m  84.3477\n",
            "     15        \u001b[36m1.3399\u001b[0m       \u001b[32m0.5138\u001b[0m        \u001b[35m1.3618\u001b[0m  84.3235\n",
            "     16        \u001b[36m1.3173\u001b[0m       \u001b[32m0.5198\u001b[0m        \u001b[35m1.3449\u001b[0m  84.3118\n",
            "     17        \u001b[36m1.2952\u001b[0m       \u001b[32m0.5267\u001b[0m        \u001b[35m1.3277\u001b[0m  84.3913\n",
            "     18        \u001b[36m1.2743\u001b[0m       \u001b[32m0.5338\u001b[0m        \u001b[35m1.3106\u001b[0m  84.4775\n",
            "     19        \u001b[36m1.2550\u001b[0m       \u001b[32m0.5388\u001b[0m        \u001b[35m1.2947\u001b[0m  84.4594\n",
            "     20        \u001b[36m1.2371\u001b[0m       \u001b[32m0.5453\u001b[0m        \u001b[35m1.2801\u001b[0m  84.4339\n",
            "     21        \u001b[36m1.2207\u001b[0m       \u001b[32m0.5500\u001b[0m        \u001b[35m1.2669\u001b[0m  84.4505\n",
            "     22        \u001b[36m1.2054\u001b[0m       \u001b[32m0.5553\u001b[0m        \u001b[35m1.2548\u001b[0m  84.3464\n",
            "     23        \u001b[36m1.1909\u001b[0m       \u001b[32m0.5577\u001b[0m        \u001b[35m1.2437\u001b[0m  84.3216\n",
            "     24        \u001b[36m1.1770\u001b[0m       \u001b[32m0.5618\u001b[0m        \u001b[35m1.2334\u001b[0m  84.3335\n",
            "     25        \u001b[36m1.1635\u001b[0m       \u001b[32m0.5649\u001b[0m        \u001b[35m1.2240\u001b[0m  84.3548\n",
            "The channel was 128, the learning rate was 0.001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.5818\u001b[0m       \u001b[32m0.5525\u001b[0m        \u001b[35m1.2597\u001b[0m  18.4915\n",
            "      2        \u001b[36m1.1701\u001b[0m       \u001b[32m0.6099\u001b[0m        \u001b[35m1.1214\u001b[0m  18.4523\n",
            "      3        \u001b[36m0.9592\u001b[0m       \u001b[32m0.6113\u001b[0m        1.1501  18.4759\n",
            "      4        \u001b[36m0.7692\u001b[0m       0.6070        1.2731  18.4905\n",
            "      5        \u001b[36m0.6075\u001b[0m       0.5912        1.4890  18.4770\n",
            "      6        \u001b[36m0.4781\u001b[0m       0.5893        1.6913  18.4727\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 256, the learning rate was 0.001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.9087\u001b[0m       \u001b[32m0.4646\u001b[0m        \u001b[35m1.4985\u001b[0m  28.5202\n",
            "      2        \u001b[36m1.3041\u001b[0m       \u001b[32m0.5743\u001b[0m        \u001b[35m1.2125\u001b[0m  28.5025\n",
            "      3        \u001b[36m1.0345\u001b[0m       \u001b[32m0.6132\u001b[0m        \u001b[35m1.1321\u001b[0m  28.5093\n",
            "      4        \u001b[36m0.8417\u001b[0m       0.5991        1.2370  28.4899\n",
            "      5        \u001b[36m0.6800\u001b[0m       0.5771        1.4647  28.4871\n",
            "      6        \u001b[36m0.5354\u001b[0m       0.5620        1.7235  28.5025\n",
            "      7        \u001b[36m0.4314\u001b[0m       0.5547        2.0688  28.5391\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 512, the learning rate was 0.001 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m2.0730\u001b[0m       \u001b[32m0.4314\u001b[0m        \u001b[35m1.5676\u001b[0m  85.0875\n",
            "      2        \u001b[36m1.4026\u001b[0m       \u001b[32m0.5414\u001b[0m        \u001b[35m1.2803\u001b[0m  85.1005\n",
            "      3        \u001b[36m1.1509\u001b[0m       \u001b[32m0.5943\u001b[0m        \u001b[35m1.1459\u001b[0m  85.1289\n",
            "      4        \u001b[36m1.0048\u001b[0m       \u001b[32m0.6064\u001b[0m        \u001b[35m1.1169\u001b[0m  85.1391\n",
            "      5        \u001b[36m0.8786\u001b[0m       \u001b[32m0.6073\u001b[0m        1.1825  85.1086\n",
            "      6        \u001b[36m0.7560\u001b[0m       0.5954        1.2917  85.0816\n",
            "      7        \u001b[36m0.6348\u001b[0m       0.5699        1.5379  85.1274\n",
            "      8        \u001b[36m0.5022\u001b[0m       0.5563        1.8122  85.1172\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 128, the learning rate was 0.01 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.9054\u001b[0m       \u001b[32m0.4023\u001b[0m        \u001b[35m1.6956\u001b[0m  18.3206\n",
            "      2        \u001b[36m1.6051\u001b[0m       \u001b[32m0.4661\u001b[0m        \u001b[35m1.5095\u001b[0m  18.3017\n",
            "      3        \u001b[36m1.4474\u001b[0m       \u001b[32m0.5057\u001b[0m        \u001b[35m1.3797\u001b[0m  18.3356\n",
            "      4        \u001b[36m1.3274\u001b[0m       \u001b[32m0.5327\u001b[0m        \u001b[35m1.2899\u001b[0m  18.3154\n",
            "      5        \u001b[36m1.2369\u001b[0m       \u001b[32m0.5571\u001b[0m        \u001b[35m1.2356\u001b[0m  18.3347\n",
            "      6        \u001b[36m1.1696\u001b[0m       \u001b[32m0.5711\u001b[0m        \u001b[35m1.1957\u001b[0m  18.3277\n",
            "      7        \u001b[36m1.1096\u001b[0m       \u001b[32m0.5843\u001b[0m        \u001b[35m1.1622\u001b[0m  18.3455\n",
            "      8        \u001b[36m1.0500\u001b[0m       \u001b[32m0.5955\u001b[0m        \u001b[35m1.1303\u001b[0m  18.3079\n",
            "      9        \u001b[36m0.9891\u001b[0m       \u001b[32m0.6080\u001b[0m        \u001b[35m1.1016\u001b[0m  18.3239\n",
            "     10        \u001b[36m0.9279\u001b[0m       \u001b[32m0.6194\u001b[0m        \u001b[35m1.0796\u001b[0m  18.3117\n",
            "     11        \u001b[36m0.8681\u001b[0m       \u001b[32m0.6273\u001b[0m        \u001b[35m1.0652\u001b[0m  18.3008\n",
            "     12        \u001b[36m0.8111\u001b[0m       \u001b[32m0.6348\u001b[0m        \u001b[35m1.0589\u001b[0m  18.3123\n",
            "     13        \u001b[36m0.7565\u001b[0m       \u001b[32m0.6388\u001b[0m        1.0623  18.3640\n",
            "     14        \u001b[36m0.7034\u001b[0m       \u001b[32m0.6394\u001b[0m        1.0760  18.3098\n",
            "     15        \u001b[36m0.6510\u001b[0m       \u001b[32m0.6413\u001b[0m        1.0982  18.3479\n",
            "     16        \u001b[36m0.5979\u001b[0m       0.6395        1.1305  18.3357\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 256, the learning rate was 0.01 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.8557\u001b[0m       \u001b[32m0.4185\u001b[0m        \u001b[35m1.6497\u001b[0m  28.1688\n",
            "      2        \u001b[36m1.5500\u001b[0m       \u001b[32m0.4838\u001b[0m        \u001b[35m1.4461\u001b[0m  28.1463\n",
            "      3        \u001b[36m1.3861\u001b[0m       \u001b[32m0.5209\u001b[0m        \u001b[35m1.3304\u001b[0m  28.1456\n",
            "      4        \u001b[36m1.2723\u001b[0m       \u001b[32m0.5455\u001b[0m        \u001b[35m1.2686\u001b[0m  28.1631\n",
            "      5        \u001b[36m1.1926\u001b[0m       \u001b[32m0.5614\u001b[0m        \u001b[35m1.2217\u001b[0m  28.1439\n",
            "      6        \u001b[36m1.1230\u001b[0m       \u001b[32m0.5780\u001b[0m        \u001b[35m1.1796\u001b[0m  28.1538\n",
            "      7        \u001b[36m1.0551\u001b[0m       \u001b[32m0.5947\u001b[0m        \u001b[35m1.1440\u001b[0m  28.1611\n",
            "      8        \u001b[36m0.9879\u001b[0m       \u001b[32m0.6083\u001b[0m        \u001b[35m1.1146\u001b[0m  28.1614\n",
            "      9        \u001b[36m0.9222\u001b[0m       \u001b[32m0.6170\u001b[0m        \u001b[35m1.0942\u001b[0m  28.1592\n",
            "     10        \u001b[36m0.8594\u001b[0m       \u001b[32m0.6240\u001b[0m        \u001b[35m1.0843\u001b[0m  28.1564\n",
            "     11        \u001b[36m0.7988\u001b[0m       \u001b[32m0.6264\u001b[0m        \u001b[35m1.0835\u001b[0m  28.1860\n",
            "     12        \u001b[36m0.7389\u001b[0m       \u001b[32m0.6292\u001b[0m        1.0908  28.1380\n",
            "     13        \u001b[36m0.6787\u001b[0m       \u001b[32m0.6317\u001b[0m        1.1075  28.1587\n",
            "     14        \u001b[36m0.6173\u001b[0m       \u001b[32m0.6335\u001b[0m        1.1374  28.1596\n",
            "     15        \u001b[36m0.5544\u001b[0m       0.6305        1.1825  28.1429\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 512, the learning rate was 0.01 and the optimizer was <class 'torch.optim.sgd.SGD'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.8205\u001b[0m       \u001b[32m0.4419\u001b[0m        \u001b[35m1.5734\u001b[0m  84.3855\n",
            "      2        \u001b[36m1.4683\u001b[0m       \u001b[32m0.5077\u001b[0m        \u001b[35m1.3682\u001b[0m  84.3265\n",
            "      3        \u001b[36m1.3082\u001b[0m       \u001b[32m0.5403\u001b[0m        \u001b[35m1.2772\u001b[0m  84.3073\n",
            "      4        \u001b[36m1.1935\u001b[0m       \u001b[32m0.5670\u001b[0m        \u001b[35m1.2119\u001b[0m  84.3392\n",
            "      5        \u001b[36m1.0966\u001b[0m       \u001b[32m0.5911\u001b[0m        \u001b[35m1.1546\u001b[0m  84.3183\n",
            "      6        \u001b[36m1.0057\u001b[0m       \u001b[32m0.6081\u001b[0m        \u001b[35m1.1128\u001b[0m  84.3274\n",
            "      7        \u001b[36m0.9206\u001b[0m       \u001b[32m0.6181\u001b[0m        \u001b[35m1.0856\u001b[0m  84.3524\n",
            "      8        \u001b[36m0.8407\u001b[0m       \u001b[32m0.6270\u001b[0m        \u001b[35m1.0719\u001b[0m  84.3451\n",
            "      9        \u001b[36m0.7642\u001b[0m       \u001b[32m0.6348\u001b[0m        \u001b[35m1.0702\u001b[0m  84.3375\n",
            "     10        \u001b[36m0.6894\u001b[0m       \u001b[32m0.6379\u001b[0m        1.0841  84.3530\n",
            "     11        \u001b[36m0.6147\u001b[0m       \u001b[32m0.6394\u001b[0m        1.1162  84.3463\n",
            "     12        \u001b[36m0.5386\u001b[0m       0.6367        1.1680  84.3471\n",
            "     13        \u001b[36m0.4607\u001b[0m       0.6283        1.2478  84.4388\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 128, the learning rate was 0.01 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m4.3382\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3035\u001b[0m  18.4610\n",
            "      2        \u001b[36m2.3038\u001b[0m       0.1000        2.3035  18.5160\n",
            "      3        2.3039       0.1000        2.3035  18.5137\n",
            "      4        2.3039       0.1000        2.3035  18.5114\n",
            "      5        2.3039       0.1000        2.3035  18.5162\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 256, the learning rate was 0.01 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1       \u001b[36m19.8248\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3034\u001b[0m  28.4841\n",
            "      2        \u001b[36m2.3038\u001b[0m       0.1000        2.3035  28.4536\n",
            "      3        2.3038       0.1000        2.3035  28.4784\n",
            "      4        2.3039       0.1000        2.3035  28.4469\n",
            "      5        2.3039       0.1000        2.3035  28.4587\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n",
            "The channel was 512, the learning rate was 0.01 and the optimizer was <class 'torch.optim.adam.Adam'>\n",
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1       \u001b[36m91.4190\u001b[0m       \u001b[32m0.1000\u001b[0m        \u001b[35m2.3033\u001b[0m  84.9767\n",
            "      2        \u001b[36m2.3038\u001b[0m       0.1000        2.3034  85.0266\n",
            "      3        2.3038       0.1000        2.3034  85.0292\n",
            "      4        2.3038       0.1000        2.3035  85.0450\n",
            "      5        2.3039       0.1000        2.3035  85.0488\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-EHKzozkRbD",
        "colab_type": "text"
      },
      "source": [
        "Write down **validation accuracy** of your model under different hyperparameter settings. Note the validation set is automatically split by Skorch during `model.fit()`.\n",
        "\n",
        "**Hint:** You may need more epochs for SGD than Adam.\n",
        "\n",
        "| #channel for each layer \\ optimizer | SGD   | Adam  |\n",
        "|-------------------------------------|-------|-------|\n",
        "| (128, 128, 128)                     | 64.13 | 65.91 |\n",
        "| (256, 256, 256)                     | 63.35 | 64.89 |\n",
        "| (512, 512, 512)                     | 63.93 | 66.12 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "go55LVSJd-vG",
        "colab_type": "text"
      },
      "source": [
        "### 2) Full CNN implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G0eCj6OmOEE",
        "colab_type": "text"
      },
      "source": [
        "Based on the CNN in the previous question, implement a full CNN model with max pooling layer.\n",
        "\n",
        "- Add a max pooling layer after each convolutional layer.\n",
        "- Each max pooling layer has a kernel size of 2 and a stride of 2.\n",
        "\n",
        "Please implement this model in the following section. You will need to tune the hyperparameters and fill the results in the table. You are also required to complete the questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMrKGlMQhCa0",
        "colab_type": "text"
      },
      "source": [
        "#### a) Implement max pooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2INt6P3Myd1",
        "colab_type": "text"
      },
      "source": [
        "Copy the CNN implementation in previous question. Implement max pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHu3Ic2dM1S9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_MaxPool(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN_MaxPool, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,512,3,padding=1)\n",
        "    self.conv2 = nn.Conv2d(512,512,3,padding=1)\n",
        "    self.conv3 = nn.Conv2d(512,512,3,padding=1)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.fc1 = nn.Linear(512*4*4,10)\n",
        "    \n",
        "    # implement parameter definitions here\n",
        "  \n",
        "  def forward(self, images):\n",
        "    #images = images.float()\n",
        "    images = self.pool(F.relu(self.conv1(images)))\n",
        "    images = self.pool(F.relu(self.conv2(images)))\n",
        "    images = self.pool(F.relu(self.conv3(images)))\n",
        "    #print(images.shape)\n",
        "    images = images.view(images.size(0), -1)\n",
        "    images = self.fc1(images)\n",
        "    # implement the forward function here\n",
        "    return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A6AEOoigq68",
        "colab_type": "text"
      },
      "source": [
        "#### b) Tune hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drH4MHSVNqwz",
        "colab_type": "text"
      },
      "source": [
        "Based on best optimizer you found in the previous problem, tune the number of channels and learning rate for best validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7povzg-4Nhrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "edff26c7-6f98-49be-cac4-9e6ef53c83c7"
      },
      "source": [
        "model = skorch.NeuralNetClassifier(CNN_MaxPool, criterion=torch.nn.CrossEntropyLoss,\n",
        "                                   device=\"cuda\",\n",
        "                                   optimizer=torch.optim.Adam,\n",
        "                                   lr=0.0001,\n",
        "                                   max_epochs=100,\n",
        "                                   batch_size=64,\n",
        "                                  callbacks=[skorch.callbacks.EarlyStopping(lower_is_better=True)],)\n",
        "\n",
        "# implement input normalization & type cast here\n",
        "train_data_normalized = torch.Tensor(train.data/255) \n",
        "train_data_normalized = train_data_normalized.permute(0,3,1,2)\n",
        "\n",
        "model.fit(train_data_normalized, np.asarray(train.targets))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss      dur\n",
            "-------  ------------  -----------  ------------  -------\n",
            "      1        \u001b[36m1.6548\u001b[0m       \u001b[32m0.5282\u001b[0m        \u001b[35m1.3343\u001b[0m  16.7617\n",
            "      2        \u001b[36m1.2446\u001b[0m       \u001b[32m0.6112\u001b[0m        \u001b[35m1.1179\u001b[0m  16.7871\n",
            "      3        \u001b[36m1.0674\u001b[0m       \u001b[32m0.6559\u001b[0m        \u001b[35m0.9982\u001b[0m  16.7890\n",
            "      4        \u001b[36m0.9457\u001b[0m       \u001b[32m0.6755\u001b[0m        \u001b[35m0.9350\u001b[0m  16.7998\n",
            "      5        \u001b[36m0.8547\u001b[0m       \u001b[32m0.6916\u001b[0m        \u001b[35m0.8925\u001b[0m  16.7792\n",
            "      6        \u001b[36m0.7818\u001b[0m       \u001b[32m0.7005\u001b[0m        \u001b[35m0.8618\u001b[0m  16.7560\n",
            "      7        \u001b[36m0.7190\u001b[0m       \u001b[32m0.7089\u001b[0m        \u001b[35m0.8419\u001b[0m  16.8500\n",
            "      8        \u001b[36m0.6625\u001b[0m       \u001b[32m0.7167\u001b[0m        \u001b[35m0.8247\u001b[0m  16.8303\n",
            "      9        \u001b[36m0.6106\u001b[0m       \u001b[32m0.7237\u001b[0m        \u001b[35m0.8100\u001b[0m  16.8161\n",
            "     10        \u001b[36m0.5605\u001b[0m       \u001b[32m0.7308\u001b[0m        \u001b[35m0.7962\u001b[0m  16.8390\n",
            "     11        \u001b[36m0.5138\u001b[0m       \u001b[32m0.7336\u001b[0m        \u001b[35m0.7851\u001b[0m  16.8361\n",
            "     12        \u001b[36m0.4679\u001b[0m       \u001b[32m0.7400\u001b[0m        \u001b[35m0.7769\u001b[0m  16.8542\n",
            "     13        \u001b[36m0.4230\u001b[0m       \u001b[32m0.7416\u001b[0m        0.7835  16.7921\n",
            "     14        \u001b[36m0.3821\u001b[0m       0.7402        0.7988  16.8363\n",
            "     15        \u001b[36m0.3428\u001b[0m       0.7375        0.8234  16.8182\n",
            "     16        \u001b[36m0.3061\u001b[0m       0.7376        0.8576  16.8274\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=CNN_MaxPool(\n",
              "    (conv1): Conv2d(3, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (fc1): Linear(in_features=8192, out_features=10, bias=True)\n",
              "  ),\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Mu2ZZHoZU0",
        "colab_type": "text"
      },
      "source": [
        "Write down the **validation accuracy** of your model under different hyperparameter settings.\n",
        "\n",
        "| #channel for each layer | validation accuracy |\n",
        "|-------------------------|---------------------|\n",
        "| (128, 128, 128)         |         72.62       |\n",
        "| (128, 256, 512)         |          74.77      |\n",
        "| (256, 256, 256)         |          73.88      |\n",
        "| (256, 512, 1024)        |          74.13       |\n",
        "| (512, 512, 512)         |          74.76        |\n",
        "| (512, 1024, 2048)       |          74.70      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UCaz8nWoWWS",
        "colab_type": "text"
      },
      "source": [
        "For the best model you have, test it on the test set.\n",
        "\n",
        "It is fine if you found some hyperparameter combination better than those listed in the tables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTtBk22OECDD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "40229a37-f53c-4837-de75-8a63b3f66889"
      },
      "source": [
        "# implement the same input normalization & type cast here\n",
        "test_data_normalized = torch.Tensor(test.data/255) \n",
        "test_data_normalized = test_data_normalized.permute(0,3,1,2)\n",
        "test.predictions = model.predict(test_data_normalized)\n",
        "sklearn.metrics.accuracy_score(test.targets, test.predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7081"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kSbhC8f1or6_"
      },
      "source": [
        "How much **test accuracy** do you get?\n",
        "\n",
        "**Your Answer:** I get 70.81% of test accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG3E9ZckomkX",
        "colab_type": "text"
      },
      "source": [
        "What can you conclude for the design of CNN structure?\n",
        "\n",
        "**Your Answer:** Regarding the first simple CNN structure, we get almost the same accuracy (around 64%) for the different hyperparameters settings. We can see that as mentionned above, the SGD optimizer required more epoches than Adam optimizer to converge. We can also see that the increase in the dimension of the channel for each layer was not beneficial in this case. Indeed, we got 65.91% validation accuracy for the channels (128,128,128) with a duration of 18 secondes per epoch, compared to 66.12% validation accuracy for the channels (512, 512, 512) with a duration of 84 secondes per epoch. Meaning much more training time for almost the same validation accuracy!\n",
        "\n",
        "Regarding the second CNN model, we added 3 MaxPooling layers (one after each convolutionnal layer) that had 2 impressive benefits. The first one is that we increased our validation accuracy by 10%, going from 64% to 74.77% (in the best cases). The second one is that we decreased our training time significantly from 84 secondes to 16 secondes per epoch for the channels configuration (512, 512, 512). We can see that by down-sampling the input dimension and by reducing its dimensionality by keeping the max values, we were able to improve our model accuracy and decrease the training time! \n",
        "In this case, we can conclude that adding layers and pooling parameters we were able to improve the model accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWO5rjXuPIH5",
        "colab_type": "text"
      },
      "source": [
        "## Recurrent Neural Networks (40 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2AmIPwBJt9j",
        "colab_type": "text"
      },
      "source": [
        "Next, let's use PyTorch to implement a recurrent neural network for sentiment analysis, i.e., classifying sentences into given sentiment labels, including positive, negative and neutral.\n",
        "\n",
        "We use a benckmark dataset (i.e., SST) for this task. First, let's download the SST dataset, and do some preprocessing to build vocabulary and split the dataset into training/validation/test sets. Also, let's define the training and evaluation function. Please do not modify the functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT8b2nr7Kq73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.LabelField()\n",
        "\n",
        "# load data splits\n",
        "train_data, val_data, test_data = datasets.SST.splits(TEXT, LABEL)\n",
        "\n",
        "# build dictionary\n",
        "TEXT.build_vocab(train_data)\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "vocab_size = len(TEXT.vocab)\n",
        "label_size = len(LABEL.vocab)\n",
        "padding_idx = TEXT.vocab.stoi['<pad>']\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "\n",
        "# build iterators\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size=32)\n",
        "\n",
        "# train a model\n",
        "# DO NOT MODIFY\n",
        "def train(model, iterator, optimizer, criterion):\n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch.text.cuda())\n",
        "        predictions = torch.max(logits, dim=-1)[1]\n",
        "        loss = criterion(logits, batch.label.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "        total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction\n",
        "\n",
        "# evaluate a model\n",
        "# DO NOT MODIFY\n",
        "def evaluate(model, iterator, criterion):  \n",
        "    total_loss, total_correct, total_prediction = 0.0, 0.0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            logits = model(batch.text.cuda())\n",
        "            predictions = torch.max(logits, dim=-1)[1]\n",
        "            loss = criterion(logits, batch.label.cuda())\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_correct += torch.eq(predictions, batch.label.cuda()).sum().item()\n",
        "            total_prediction += batch.label.size(0)\n",
        "    return total_loss / len(iterator), total_correct / total_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbWxFDZdK6rf",
        "colab_type": "text"
      },
      "source": [
        "Next, we are ready to build our RNN model for sentiment analysis. In the following codes, we have provided several hyperparameters we needed for building the model, including vocabulary size (vocab_size), the word embedding dimension (embedding_dim), the hidden layer dimension (hidden_dim), the number of layers (num_layers) and the number of sentence labels (label_size). Please fill in the missing codes, and implement an LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWUKPgDGNQSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, label_size, padding_idx):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.label_size = label_size\n",
        "        self.num_layers = 1\n",
        "\n",
        "        # add the layers required for sentiment analysis.\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=self.num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim,label_size)\n",
        "         \n",
        "\n",
        "    def zero_state(self, batch_size): \n",
        "        # implement the function, which returns an initial hidden state.\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).cuda() # hidden state\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).cuda() # cell state\n",
        "        return h0, c0\n",
        "\n",
        "    def forward(self, text):\n",
        "        # implement the forward function of the model.\n",
        "        h0, c0 = self.zero_state(text.size(0))\n",
        "        embedding = self.embedding(text)\n",
        "        output , (h0, c0) = self.lstm(embedding, (h0, c0))\n",
        "        output = self.fc(output)\n",
        "        output = F.log_softmax(output[:, -1, :], dim=1)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBX_xc9MN0gw",
        "colab_type": "text"
      },
      "source": [
        "Finally, we are ready to train the model and compute the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQrU0wuUOIgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "701bbca2-028b-4bdf-886b-a35849f471de"
      },
      "source": [
        "model = RNNClassifier(vocab_size, embedding_dim, hidden_dim, label_size, padding_idx)\n",
        "# tune the optimizer type and hyperparameters here\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.cuda()\n",
        "criterion.cuda()\n",
        "\n",
        "# train and test the model\n",
        "# DO NOT MODIFY\n",
        "best_valid_acc = 0.0\n",
        "best_state_dict = copy.deepcopy(model.state_dict())\n",
        "for epoch in range(20):\n",
        "    train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n",
        "\n",
        "    print('Epoch {} | Train loss {:.3f} | Valid loss {:.3f} | Valid acc {:.3f} | Train acc {:.3f}'.format(epoch, train_loss, valid_loss, valid_acc, train_acc))\n",
        "\n",
        "    if valid_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_acc\n",
        "        best_state_dict = copy.deepcopy(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 | Train loss 1.052 | Valid loss 1.043 | Valid acc 0.405 | Train acc 0.412\n",
            "Epoch 1 | Train loss 1.047 | Valid loss 1.058 | Valid acc 0.403 | Train acc 0.423\n",
            "Epoch 2 | Train loss 1.043 | Valid loss 1.097 | Valid acc 0.371 | Train acc 0.422\n",
            "Epoch 3 | Train loss 1.034 | Valid loss 1.163 | Valid acc 0.446 | Train acc 0.430\n",
            "Epoch 4 | Train loss 0.987 | Valid loss 1.109 | Valid acc 0.494 | Train acc 0.521\n",
            "Epoch 5 | Train loss 0.857 | Valid loss 1.125 | Valid acc 0.540 | Train acc 0.626\n",
            "Epoch 6 | Train loss 0.713 | Valid loss 1.187 | Valid acc 0.532 | Train acc 0.703\n",
            "Epoch 7 | Train loss 0.564 | Valid loss 1.238 | Valid acc 0.540 | Train acc 0.768\n",
            "Epoch 8 | Train loss 0.455 | Valid loss 1.306 | Valid acc 0.543 | Train acc 0.818\n",
            "Epoch 9 | Train loss 0.364 | Valid loss 1.359 | Valid acc 0.542 | Train acc 0.859\n",
            "Epoch 10 | Train loss 0.281 | Valid loss 1.450 | Valid acc 0.524 | Train acc 0.900\n",
            "Epoch 11 | Train loss 0.216 | Valid loss 1.520 | Valid acc 0.550 | Train acc 0.930\n",
            "Epoch 12 | Train loss 0.173 | Valid loss 1.657 | Valid acc 0.530 | Train acc 0.946\n",
            "Epoch 13 | Train loss 0.148 | Valid loss 1.569 | Valid acc 0.557 | Train acc 0.956\n",
            "Epoch 14 | Train loss 0.114 | Valid loss 1.732 | Valid acc 0.535 | Train acc 0.966\n",
            "Epoch 15 | Train loss 0.094 | Valid loss 1.661 | Valid acc 0.534 | Train acc 0.972\n",
            "Epoch 16 | Train loss 0.090 | Valid loss 1.715 | Valid acc 0.528 | Train acc 0.973\n",
            "Epoch 17 | Train loss 0.072 | Valid loss 1.780 | Valid acc 0.530 | Train acc 0.979\n",
            "Epoch 18 | Train loss 0.058 | Valid loss 1.699 | Valid acc 0.546 | Train acc 0.985\n",
            "Epoch 19 | Train loss 0.050 | Valid loss 1.855 | Valid acc 0.522 | Train acc 0.986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EgT69I1reZ4",
        "colab_type": "text"
      },
      "source": [
        "Once we find the best hyperparameters for the validation set, we can now evaluate our model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPDvglccrdWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98910c7b-14c9-41a8-94e5-9ed3f0f32286"
      },
      "source": [
        "model.load_state_dict(best_state_dict)\n",
        "test_loss, test_acc = evaluate(model, test_iter, criterion)\n",
        "print('Test loss {:.3f} | Test acc {:.3f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss 1.518 | Test acc 0.608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbqSAz90zBYi",
        "colab_type": "text"
      },
      "source": [
        "### 1) Implement the RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_5KEDzgzVxT",
        "colab_type": "text"
      },
      "source": [
        "The current codes of the RNN model are not complete, so let's first complete the codes to implement a standard RNN model by filling in the [block](https://colab.research.google.com/drive/1mhhF9FPHSmePtVQrhNBwRujfUkOjUspj#scrollTo=kWUKPgDGNQSr)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiDCl9J0zIKO",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 1-1: Creating all the Required Layers in Your Model**\n",
        "\n",
        "Remember that when building a deep learning model, we first need to complete the **init** function by creating all the required layers. In our case, since we are using RNNs for sentence classification, we need an embedding layer to transform words into word embeddings, a RNN layer to transform word embeddings into sentence encodings, an activation function, and a linear layer as well as a softmax function for sentence classification.\n",
        "\n",
        "Based on that, please create all the necessary layers of your RNN model in the **init** function. Note that we have already added the word embedding layer for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF_dE-TqzL0A",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 1-2: Implementing the Function for Initializing Hidden States**\n",
        "\n",
        "Remember that when applying a RNN unit to transform word embeddings into sentence encodings, the RNN unit starts from an initial hidden vector with all zero values, and sequentially read each word to update the hidden vector. Finally, the hidden vector obtained after reading the last word is treated as the sentence encoding.\n",
        "\n",
        "In this step, please implement the **zero_state** function, which returns a batch of initial hidden vectors given a batch size. Hint: your function should return a tensor with all the values being zero, and you may refer to the [official document](https://pytorch.org/docs/stable/nn.html#rnn) for the correct shape of the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGiPTOnY28Iq",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 1-3: Implementing the Forward Function**\n",
        "\n",
        "Finally, we are ready to build the forward function, which takes a batch of sentences as inputs and returns the a batch of logits. To be more specific, the input is given by the tensor called $\\text{text}$, and the size of the tensor is $(B, L)$, with $B$ being the batch size, $L$ being the maximum length of sentencees in this batch and $\\text{text}[i, j]$ being the interger id of the $j$-th word in the $i$-th sentence. Given this tensor as input, your forward function should return a logit tensor of size $(B, C)$, with $B$ being the batch size and $C$ being the number of possible classes.\n",
        "\n",
        "Please implement the forward function based on the above instructions. Note that we have already applied the word embedding layer to the text input, and obtained a tensor called $\\text{embedding}$, and the size of the tensor is $(B, L, D)$, where $D$ is the word embedding dimension. You can directly operate on the $\\text{embedding}$ tensor to compute the logits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUL9zYw4y_IZ",
        "colab_type": "text"
      },
      "source": [
        "### 2) Compare Different Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKKFSkzzUA_",
        "colab_type": "text"
      },
      "source": [
        "In the previous task, we have implemented a RNN model for sentiment analysis, or more generally sentence classification.\n",
        "\n",
        "To better understand several concepts in deep learning, let's do some ablation studies by using the model we have just implemented.\n",
        "\n",
        "The first task is to try different optimizers for your model, where for each optimizer, you may also try different options of learning rate. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNlnDbZtqHgi",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 2-1: Completing the Table**\n",
        "\n",
        "We have provided the following table for different combinations of optimizers and learning rate, please write down the **validation accuracy** of your model with different optimizers and learning rates.\n",
        "\n",
        "|         | 0.1  | 0.01 | 0.001|0.0001|\n",
        "|---------|------|------|------|------|\n",
        "| SGD     |  40.8|   40.8   |   40.0   |   42.5   |\n",
        "| Adam    |   53.2   |     50.7 |     55.3 |   48.4   |\n",
        "| RMSprop |    48.0  |    49.4  |   53.3   |   50.2   |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVVd5b9rzSFA",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 2-2: Explaining your Observations**\n",
        "\n",
        "Based on your results, briefly explain your observations, e.g., which optimizer works the best, what is the optimal learning rate for each optimizer?\n",
        "\n",
        "*Your Answer:* According to the results we can see that the optimizer that work the best is Adam. It's optimal learning rate was 0.001 to get a validation accuracy of 55.3%. This learning rate of 0.001 was also the best for RMSprop has it got its highest accuracy score of 53.3%. For both Adam and RMSprop, the validation accuracy was fluctuating a lot, going from 53.2% to ~25% to ~50%, etc, when the learning rate was high (e.g 0.1). It seems that theses optimizers were not able to find a local optima when the learning rate was too high.\n",
        "\n",
        "Regarding SGD, for this optimizer the validation accuracy was not fluctuating when the learning rate was too high, but stayed stuck at around 40% validation accuracy for a learning rate of 0.1. For the lower learning rates, the model was learning too slowly and would have require more than 20 epoches to maybe get a score as good as Adam.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyy7qpHtzYJn",
        "colab_type": "text"
      },
      "source": [
        "### 3) Compare the Results under Different Epoches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXQERRizZO6",
        "colab_type": "text"
      },
      "source": [
        "In this task, we hope to compare the results of our model under different training epoches, and answer a question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JBBjTGd1zis",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 3-1: Completing the Table**\n",
        "\n",
        "We have provided the following table, please write down the **training accuracy** and **validation accuracy** of your model under different epoches.\n",
        "\n",
        "|                    |  10  |  20  |  30  |  40  |  50  |\n",
        "|--------------------|------|------|------|------|------|\n",
        "| Training Accuracy  |  79.4    |  94.7    |    97.4  |   98.9   |  99.7    |\n",
        "| Validation Accuracy|  55.2      |  55.0      |  54.5     |  55.3      | 56.0      |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l82_FjXazdod",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 3-2: Answering the Question**\n",
        "\n",
        "Is it always better to train a model for more epoches? How can we decide when should we stop training?\n",
        "\n",
        "*Your Answer:* No it is not always better to train a model for more epoches since we will start to overfit. In our case, the model was able to reach its maximum accuracy on the validation set pretty quickly: 56.9% at epoch 12. This means that we should have stopped the training process here, at this epoch, since there were no improvement after, from epoch 12 to 50. Morever, we can see that the training loss kept decreasing, showing that the model was starting to overfit the training dataset and therefore to generalize poorly, as we can see that the validation loss started to increase more and more. Indeed, when training loss << validation loss, this means that we are overfitting which was the case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "066JcRvAze7f",
        "colab_type": "text"
      },
      "source": [
        "### 4) Compare Different Model Capacities/Configurations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agxhZpHYzjIR",
        "colab_type": "text"
      },
      "source": [
        "In practice, we may also vary the capacity of our model to find the optimal choice. In this part, please try different configurations of your model, which have different model capacities. Based on your observation, please also answer a question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fp2QC2Pzkja",
        "colab_type": "text"
      },
      "source": [
        "- **Subtask 4-1: Completing the Table**\n",
        "\n",
        "Please write down the **validation accuracy** of your model under different model capacities (i.e., specified by the word embedding dimension and the hidden layer dimension).\n",
        "\n",
        "|Embedding dim / Hidden dim |  64  |  128  |  256 |\n",
        "|---------------------------|------|-------|------|\n",
        "| 64                        |  54.7    |   55.8    | 58.4     |\n",
        "| 128                       |   57.4   |    56.0   |  55.7    |\n",
        "| 256                       |    56.7  |     57.6  |  57.3    |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mY-OzP6E4JWU"
      },
      "source": [
        "- **Subtask 4-2: Answering the Question**\n",
        "\n",
        "Is it always better to increase model capacities in this case? Is it always better to increase model capacities in general? How to decide a proper model capacity in practice?\n",
        "\n",
        "*Your Answer:* In our case, increasing the model capacity to 256 for the hidden dimension is beneficial when the Embedding dimension is 64 as we can see a 3.7% increase in the validation accuracy. However, when the Embedding dimension is bigger: 128 and 256, increasing the Hidden Dimension size doesn't seem to add any value as the validation accuracy is almost the same 57% ~ 55%. In our case, we can consider that the model is almost able to get the same validation accuracy for different model capacity. \n",
        "\n",
        "We cannot say that it is always better to increase model capacities in general. As the model capacity refers to the ability for the model to learn more features and complex patterns in the dataset, it really depends on our dataset and the task we want to achieve in order to know if we should decrease or increase the model capacity. This means that a model with a low capacity would tend to underfit and a model with a high capacity would tend to overfit the data.\n",
        "In practice, we will try to maximize validation error performance while trying to minimize the model capacity. We will use cross validation to test the best hyperparameters on the test set and we will use some regularization techniques such as L1, L2 or dropout in order to limit the model capacity and avoid overfitting.\n"
      ]
    }
  ]
}